# GNewsæŠ€èƒ½ä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

GNewsæŠ€èƒ½æ˜¯ä¸€ä¸ªåŸºäºGNews APIçš„æ–°é—»è·å–å·¥å…·ï¼Œæ”¯æŒè·å–å¤´æ¡æ–°é—»ã€æœç´¢æ–°é—»å’Œä¿å­˜æ–°é—»æ•°æ®åˆ°æ–‡ä»¶ã€‚

## ğŸ”§ å®‰è£…ä¸é…ç½®

### 1. è·å–API Key
1. è®¿é—® https://gnews.io/
2. æ³¨å†Œè´¦å·å¹¶ç™»å½•
3. åœ¨Dashboardä¸­è·å–æ‚¨çš„API Key

### 2. é…ç½®ç¯å¢ƒå˜é‡
åˆ›å»º `.env` æ–‡ä»¶ï¼ˆå‚è€ƒ `.env.example`ï¼‰ï¼š
```bash
GNEWS_API_KEY=your_actual_api_key_here
```

### 3. éªŒè¯é…ç½®
è¿è¡Œæµ‹è¯•è„šæœ¬ï¼š
```bash
python test_gnews_skill.py
```

## ğŸ› ï¸ å¯ç”¨å·¥å…·

### 1. `get_gnews_headlines` - è·å–å¤´æ¡æ–°é—»
**å‚æ•°ï¼š**
- `country` (str): å›½å®¶ä»£ç ï¼Œé»˜è®¤ 'us'
- `category` (str): æ–°é—»ç±»åˆ«ï¼Œé»˜è®¤ 'general'
  - å¯é€‰å€¼: general, business, technology, sports, health, science, entertainment
- `max_results` (int): æœ€å¤§è¿”å›ç»“æœæ•°ï¼Œé»˜è®¤ 10
- `language` (str): è¯­è¨€ä»£ç ï¼Œé»˜è®¤ 'en'

**ç¤ºä¾‹ï¼š**
```python
# è·å–ç¾å›½ç§‘æŠ€æ–°é—»
result = get_gnews_headlines(
    country="us",
    category="technology",
    max_results=5,
    language="en"
)
```

### 2. `search_gnews` - æœç´¢æ–°é—»
**å‚æ•°ï¼š**
- `query` (str): æœç´¢å…³é”®è¯ï¼ˆå¿…éœ€ï¼‰
- `language` (str): è¯­è¨€ä»£ç ï¼Œé»˜è®¤ 'en'
- `country` (str): å›½å®¶ä»£ç ï¼Œé»˜è®¤ 'us'
- `max_results` (int): æœ€å¤§è¿”å›ç»“æœæ•°ï¼Œé»˜è®¤ 10
- `from_date` (str): å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DD
- `to_date` (str): ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DD
- `sort_by` (str): æ’åºæ–¹å¼ï¼Œé»˜è®¤ 'relevance'
  - å¯é€‰å€¼: relevance, publishedAt

**ç¤ºä¾‹ï¼š**
```python
# æœç´¢äººå·¥æ™ºèƒ½ç›¸å…³æ–°é—»
result = search_gnews(
    query="artificial intelligence",
    language="en",
    max_results=10,
    from_date="2024-01-01",
    sort_by="publishedAt"
)
```

### 3. `save_news_to_file` - ä¿å­˜æ–°é—»æ•°æ®
**å‚æ•°ï¼š**
- `news_data` (dict): æ–°é—»æ•°æ®ï¼ˆä»ä¸Šè¿°å·¥å…·è·å–ï¼‰
- `file_path` (str): æ–‡ä»¶ä¿å­˜è·¯å¾„
- `format` (str): ä¿å­˜æ ¼å¼ï¼Œé»˜è®¤ 'json'
  - å¯é€‰å€¼: json, txt

**ç¤ºä¾‹ï¼š**
```python
# ä¿å­˜ä¸ºJSONæ ¼å¼
save_news_to_file(
    news_data=result,
    file_path="news_data.json",
    format="json"
)

# ä¿å­˜ä¸ºæ–‡æœ¬æ ¼å¼
save_news_to_file(
    news_data=result,
    file_path="news_summary.txt",
    format="txt"
)
```

## ğŸ“Š æ•°æ®æ ¼å¼

### æˆåŠŸå“åº”æ ¼å¼ï¼š
```json
{
  "success": true,
  "total_articles": 10,
  "articles": [
    {
      "title": "æ–°é—»æ ‡é¢˜",
      "description": "æ–°é—»æè¿°",
      "content": "æ–°é—»å†…å®¹",
      "url": "æ–°é—»é“¾æ¥",
      "image": "å›¾ç‰‡é“¾æ¥",
      "published_at": "å‘å¸ƒæ—¶é—´",
      "source": {
        "name": "æ¥æºåç§°",
        "url": "æ¥æºé“¾æ¥"
      }
    }
  ],
  "request_info": {
    "country": "us",
    "category": "technology",
    "max_results": 10,
    "language": "en"
  }
}
```

### é”™è¯¯å“åº”æ ¼å¼ï¼š
```json
{
  "success": false,
  "error": "é”™è¯¯æè¿°",
  "suggestion": "è§£å†³å»ºè®®"
}
```

## ğŸŒ æ”¯æŒçš„å›½å®¶å’Œè¯­è¨€

### å›½å®¶ä»£ç ï¼š
- `us` - ç¾å›½
- `gb` - è‹±å›½
- `cn` - ä¸­å›½
- `jp` - æ—¥æœ¬
- `in` - å°åº¦
- `au` - æ¾³å¤§åˆ©äºš
- `ca` - åŠ æ‹¿å¤§
- æ›´å¤šå›½å®¶è¯·å‚è€ƒGNewsæ–‡æ¡£

### è¯­è¨€ä»£ç ï¼š
- `en` - è‹±è¯­
- `zh` - ä¸­æ–‡
- `ja` - æ—¥è¯­
- `ko` - éŸ©è¯­
- `fr` - æ³•è¯­
- `de` - å¾·è¯­
- `es` - è¥¿ç­ç‰™è¯­
- æ›´å¤šè¯­è¨€è¯·å‚è€ƒGNewsæ–‡æ¡£

## ğŸ” ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šè·å–ä¸­æ–‡ç§‘æŠ€æ–°é—»
```python
result = get_gnews_headlines(
    country="cn",
    category="technology",
    language="zh",
    max_results=5
)
```

### ç¤ºä¾‹2ï¼šæœç´¢ç‰¹å®šæ—¥æœŸèŒƒå›´çš„æ–°é—»
```python
result = search_gnews(
    query="bitcoin",
    from_date="2024-01-01",
    to_date="2024-01-31",
    sort_by="publishedAt",
    max_results=20
)
```

### ç¤ºä¾‹3ï¼šå®Œæ•´å·¥ä½œæµç¨‹
```python
# 1. æœç´¢æ–°é—»
search_result = search_gnews(
    query="climate change",
    language="en",
    max_results=10
)

# 2. æ£€æŸ¥ç»“æœ
if search_result.get("success"):
    # 3. ä¿å­˜ä¸ºJSON
    save_news_to_file(
        news_data=search_result,
        file_path="climate_news.json",
        format="json"
    )
    
    # 4. ä¿å­˜ä¸ºæ–‡æœ¬æ‘˜è¦
    save_news_to_file(
        news_data=search_result,
        file_path="climate_news_summary.txt",
        format="txt"
    )
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **APIé™åˆ¶**ï¼šGNews APIæœ‰è°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œè¯·å‚è€ƒå®˜æ–¹æ–‡æ¡£
2. **ç¯å¢ƒå˜é‡**ï¼šç¡®ä¿ `.env` æ–‡ä»¶åœ¨é¡¹ç›®æ ¹ç›®å½•
3. **é”™è¯¯å¤„ç†**ï¼šæ‰€æœ‰å·¥å…·éƒ½åŒ…å«å®Œå–„çš„é”™è¯¯å¤„ç†
4. **ç½‘ç»œè¿æ¥**ï¼šéœ€è¦ç¨³å®šçš„ç½‘ç»œè¿æ¥è®¿é—®API
5. **æ•°æ®æ ¼å¼**ï¼šAPIå“åº”æ ¼å¼å¯èƒ½å˜æ›´ï¼Œè¯·å…³æ³¨å®˜æ–¹æ›´æ–°

## ğŸ”— ç›¸å…³é“¾æ¥

- [GNewså®˜æ–¹ç½‘ç«™](https://gnews.io/)
- [GNews APIæ–‡æ¡£](https://docs.gnews.io/)
- [API Keyè·å–](https://gnews.io/account)
- [å›½å®¶ä»£ç åˆ—è¡¨](https://gnews.io/docs/v4#countries)
- [è¯­è¨€ä»£ç åˆ—è¡¨](https://gnews.io/docs/v4#languages)

## ğŸš€ é«˜çº§ç”¨æ³•

### æ‰¹é‡å¤„ç†æ–°é—»
```python
# è·å–å¤šä¸ªç±»åˆ«çš„æ–°é—»
categories = ["technology", "business", "science"]
all_news = []

for category in categories:
    result = get_gnews_headlines(
        category=category,
        max_results=3
    )
    if result.get("success"):
        all_news.extend(result.get("articles", []))

print(f"æ€»å…±è·å–äº† {len(all_news)} æ¡æ–°é—»")
```

### å®šæ—¶è·å–æ–°é—»
```python
import schedule
import time

def daily_news_update():
    result = get_gnews_headlines(
        category="general",
        max_results=5
    )
    if result.get("success"):
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        save_news_to_file(
            news_data=result,
            file_path=f"news_daily_{timestamp}.json"
        )

# æ¯å¤©9ç‚¹æ‰§è¡Œ
schedule.every().day.at("09:00").do(daily_news_update)

while True:
    schedule.run_pending()
    time.sleep(60)
```

---

**ğŸ“ æŠ€æœ¯æ”¯æŒ**
å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒï¼š
1. æ£€æŸ¥API Keyæ˜¯å¦æ­£ç¡®
2. æ£€æŸ¥ç½‘ç»œè¿æ¥
3. æŸ¥çœ‹é”™è¯¯ä¿¡æ¯ä¸­çš„å»ºè®®
4. å‚è€ƒGNewså®˜æ–¹æ–‡æ¡£